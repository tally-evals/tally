---
title: Builtin Metrics
description: Prebuilt metric definitions for common evaluation needs.
---

import { PropertyTable } from '@/components/PropertyTable';

# Builtin Metrics

Prebuilt metrics are exported from the `@tally-evals/tally/metrics` entrypoint. They provide ready-to-use evaluation capabilities for common use cases.

## Import

```ts
import {
  // Single-turn metrics
  createAnswerRelevanceMetric,
  createAnswerSimilarityMetric,
  createCompletenessMetric,
  createToxicityMetric,
  createToolCallAccuracyMetric,
  // Multi-turn metrics
  createRoleAdherenceMetric,
  createGoalCompletionMetric,
  createTopicAdherenceMetric,
} from '@tally-evals/tally/metrics';
```

---

## Single-Turn Metrics

### `createAnswerRelevanceMetric()`

Measures how relevant the assistant's response is to the user's query. Uses LLM-as-judge to score relevance on a 0–5 scale, normalized to 0–1.

<PropertyTable
  content={[
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for relevance analysis.',
    },
    {
      name: 'partialWeight',
      type: 'number',
      description: 'Weight for "unsure" statements in the rubric.',
      isOptional: true,
      defaultValue: '0.3',
    },
    {
      name: 'aggregators',
      type: 'NumericAggregatorDef[]',
      description: 'Custom numeric aggregators. Defaults include percentiles.',
      isOptional: true,
    },
  ]}
/>

---

### `createAnswerSimilarityMetric()`

Measures semantic similarity between the response and a target/expected answer. Can use embeddings or keyword matching.

<PropertyTable
  content={[
    {
      name: 'embeddingModel',
      type: 'EmbeddingModel',
      description: 'Optional embedding model for semantic similarity.',
      isOptional: true,
    },
    {
      name: 'targetResponse',
      type: 'string',
      description: 'Target response to compare against. Can also be provided via metadata.targetResponse.',
      isOptional: true,
    },
    {
      name: 'minKeywords',
      type: 'number',
      description: 'Minimum matching keywords required (keyword mode).',
      isOptional: true,
      defaultValue: '1',
    },
  ]}
/>

---

### `createCompletenessMetric()`

Measures whether the response fully addresses all aspects of the query. Uses LLM-as-judge to score on a 0–5 scale, normalized to 0–1.

<PropertyTable
  content={[
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for completeness analysis.',
    },
    {
      name: 'expectedPoints',
      type: 'string[]',
      description: 'Expected key points/topics to check for coverage.',
      isOptional: true,
    },
    {
      name: 'aggregators',
      type: 'NumericAggregatorDef[]',
      description: 'Custom numeric aggregators.',
      isOptional: true,
    },
  ]}
/>

---

### `createToxicityMetric()`

Detects harmful, offensive, or inappropriate content in responses. Returns a toxicity score where lower is better.

<PropertyTable
  content={[
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for toxicity detection.',
    },
    {
      name: 'categories',
      type: "Array<'hate' | 'harassment' | 'violence' | 'self-harm' | 'sexual' | 'profanity'>",
      description: 'Toxicity categories to emphasize during evaluation.',
      isOptional: true,
    },
  ]}
/>

---

### `createToolCallAccuracyMetric()`

Validates that the agent made correct tool calls with proper arguments. Checks tool names, argument schemas, and optionally call order.

<PropertyTable
  content={[
    {
      name: 'expectedToolCalls',
      type: 'Array<{ toolName: string; argsSchema?: z.ZodSchema }>',
      description: 'Expected tool calls to validate against.',
      properties: [
        {
          type: 'ExpectedToolCall',
          parameters: [
            {
              name: 'toolName',
              type: 'string',
              description: 'Name of the expected tool.',
            },
            {
              name: 'argsSchema',
              type: 'z.ZodSchema',
              description: 'Zod schema for validating tool arguments.',
              isOptional: true,
            },
          ],
        },
      ],
    },
    {
      name: 'toolCallOrder',
      type: 'string[]',
      description: 'Expected order of tool calls (array of tool names).',
      isOptional: true,
    },
    {
      name: 'strictMode',
      type: 'boolean',
      description: 'If true, sequence must be exact with no extra calls.',
      isOptional: true,
      defaultValue: 'false',
    },
  ]}
/>

---

## Multi-Turn Metrics

### `createRoleAdherenceMetric()`

Measures how well the assistant maintains its assigned role/persona across the entire conversation. Multi-turn metric.

<PropertyTable
  content={[
    {
      name: 'expectedRole',
      type: 'string',
      description: 'Description of the role the assistant should adhere to.',
    },
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for role adherence analysis.',
    },
    {
      name: 'checkConsistency',
      type: 'boolean',
      description: 'Whether to evaluate consistency across all turns.',
      isOptional: true,
      defaultValue: 'true',
    },
  ]}
/>

---

### `createGoalCompletionMetric()`

Measures whether the conversation achieved its intended goal. Evaluates progress and final outcome across all turns. Multi-turn metric.

<PropertyTable
  content={[
    {
      name: 'goal',
      type: 'string',
      description: 'Description of the goal to evaluate against.',
    },
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for goal completion analysis.',
    },
    {
      name: 'checkPartialCompletion',
      type: 'boolean',
      description: 'Whether to reward partial progress toward the goal.',
      isOptional: true,
      defaultValue: 'true',
    },
    {
      name: 'considerEfficiency',
      type: 'boolean',
      description: 'Whether to consider efficiency (fewer turns) in scoring.',
      isOptional: true,
      defaultValue: 'false',
    },
  ]}
/>

---

### `createTopicAdherenceMetric()`

Measures whether the assistant stays on topic throughout the conversation. Detects off-topic tangents and topic drift. Multi-turn metric.

<PropertyTable
  content={[
    {
      name: 'topics',
      type: 'string[]',
      description: 'Topics the assistant should adhere to.',
    },
    {
      name: 'provider',
      type: 'LanguageModel',
      description: 'AI SDK language model for topic adherence analysis.',
    },
    {
      name: 'allowTopicTransitions',
      type: 'boolean',
      description: 'If true, allows natural transitions between related topics.',
      isOptional: true,
      defaultValue: 'true',
    },
    {
      name: 'strictMode',
      type: 'boolean',
      description: 'If true, penalizes deviations more strictly.',
      isOptional: true,
      defaultValue: 'false',
    },
  ]}
/>

---

## Example

```ts
import { google } from '@ai-sdk/google';
import {
  createAnswerRelevanceMetric,
  createRoleAdherenceMetric,
} from '@tally-evals/tally/metrics';
import { defineSingleTurnEval, defineMultiTurnEval, thresholdVerdict } from '@tally-evals/tally';

const model = google('models/gemini-2.5-flash-lite');

// Single-turn metric
const relevance = createAnswerRelevanceMetric({ provider: model });
const relevanceEval = defineSingleTurnEval({
  name: 'Answer Relevance',
  metric: relevance,
  verdict: thresholdVerdict(0.7),
});

// Multi-turn metric
const roleAdherence = createRoleAdherenceMetric({
  expectedRole: 'helpful customer support agent',
  provider: model,
});
const roleEval = defineMultiTurnEval({
  name: 'Role Adherence',
  metric: roleAdherence,
  verdict: thresholdVerdict(0.8),
});
```
