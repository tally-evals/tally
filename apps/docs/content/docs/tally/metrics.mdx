---
title: Metrics
description: Measuring agent behavior with LLM and code-based metrics.
---

Metrics are the foundation of evaluation in Tally. They produce a value (usually normalized between 0 and 1) that represents a specific quality of the agent's behavior.

## Built-in Metrics

Tally comes with a set of pre-built metrics that use LLMs to evaluate responses.

### Single-Turn Metrics

| Metric | Description |
| :--- | :--- |
| `answerRelevance` | How relevant is the response to the user's input? |
| `completeness` | Does the response address all parts of the user's query? |
| `toxicity` | Checks for harmful or offensive content in the response. |
| `toolCallAccuracy` | Validates that the agent called the correct tools with correct params. |

### Multi-Turn Metrics

| Metric | Description |
| :--- | :--- |
| `roleAdherence` | Does the agent maintain its assigned persona throughout? |
| `goalCompletion` | Did the agent successfully achieve the user's goal? |
| `topicAdherence` | Did the agent stay on topic across multiple turns? |

## Custom Metrics

You can define your own metrics using `defineBaseMetric`.

### Code-Based Metric

```ts
import { defineBaseMetric } from '@tally-evals/tally';

const lengthMetric = defineBaseMetric({
  name: 'ResponseLength',
  evaluate: async (target) => {
    const text = target.output[0].content;
    return text.length > 100 ? 1 : 0.5; // Simple example
  }
});
```

### LLM-Based Metric

Tally provides helpers to create custom LLM-based metrics with your own prompts.

```ts
import { createLlmMetric } from '@tally-evals/tally/metrics';

const creativeMetric = createLlmMetric({
  name: 'Creativity',
  prompt: 'Rate the creativity of this response from 1 to 10...',
  provider: model,
});
```
